{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author - Sidhanta Narayan Singhdeo\n",
    "\n",
    "### CWID  - 10465272\n",
    "### Course - AAI 800 (Special Problems in AI)\n",
    "### Project Advisor - Prof. Hong Man"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Evaluation Build\n",
    "\n",
    "* The FL Architecture implemented below is taregted to perform client metric Evaluation.\n",
    "* The TFF framework will require defining custom variable, metrics and iterative functions\n",
    "* The client models will be aggregated and we will see the performance after th global broadcast on the same\n",
    "* To run evaluation on local model, run the below for only 1 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch asyncio to allow nested event loops\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required Libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import functools\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Keras models \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deactivates GPU execution, to tun on GPU set to [0,1,2..] depending on number of GPUs\n",
    "# Switched to CPU as GPU was giving errors due to limited memory\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot detect physical GPU device in TF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check GPUis switched off\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if not gpu_devices:\n",
    "  print('Cannot detect physical GPU device in TF')\n",
    "\n",
    "# If using GPU , use the below to restrict memory usage \n",
    "# This will work fine , but will slow the computation as all memory is not used.\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     gpu_devices[0], \n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=5120),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=5120)])\n",
    "# tf.config.list_logical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check TFF computation is running correctly\n",
    "@tff.federated_computation\n",
    "def hello_world():\n",
    "  return 'Hello, World!'\n",
    "\n",
    "hello_world()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Section\n",
    "Select values for parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_number_of_clients = 2\n",
    "NUMBER_OF_CLIENTS = int(input(\"Enter Number of Clients: \") or default_number_of_clients)\n",
    "\n",
    "default_number_of_rounds = 10\n",
    "NUMBER_OF_ROUNDS = int(input(\"Enter Number of Rounds: \") or default_number_of_rounds )\n",
    "\n",
    "default_client_dataset_size = 500\n",
    "MAX_CLIENT_DATASET_SIZE = int(input(\"Enter Max Client Datset Size: \") or default_client_dataset_size)\n",
    "\n",
    "default_client_epochs_per_round = 1\n",
    "CLIENT_EPOCHS_PER_ROUND = int(input(\"Enter Client Epochs pe round: \") or default_client_epochs_per_round)\n",
    "\n",
    "default_client_batch_size = 20\n",
    "CLIENT_BATCH_SIZE = int(input(\"Enter Client Batch Size: \") or default_client_batch_size)\n",
    "\n",
    "default_client_test_batch_size = 100\n",
    "TEST_BATCH_SIZE = int(input(\"Enter Test Batch Size: \") or default_client_test_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: /2/10/500/1/20\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = '/'+str(NUMBER_OF_CLIENTS)+'/'+str(NUMBER_OF_ROUNDS)+'/'+str(MAX_CLIENT_DATASET_SIZE)+'/'+str(CLIENT_EPOCHS_PER_ROUND)+'/'+str(CLIENT_BATCH_SIZE)\n",
    "print('Hyperparameters:', hyperparameters) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR 100 Data \n",
    "The simulation Datasets have predefined clients which are subsets of the whole dataset\n",
    "No need to create seperate clients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_test = tff.simulation.datasets.cifar100.load_data(cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('coarse_label', TensorSpec(shape=(), dtype=tf.int64, name=None)),\n",
       "             ('image',\n",
       "              TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None)),\n",
       "             ('label', TensorSpec(shape=(), dtype=tf.int64, name=None))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data type\n",
    "cifar_train.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data from a sample\n",
    "example_dataset = cifar_train.create_tf_dataset_for_client(cifar_train.client_ids[0])\n",
    "example_element= next(iter(example_dataset))\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 32, 3), dtype=uint8, numpy=\n",
       "array([[[ 89,  71,  73],\n",
       "        [120,  98, 106],\n",
       "        [137, 113, 116],\n",
       "        ...,\n",
       "        [133, 105, 102],\n",
       "        [131, 104,  98],\n",
       "        [142, 121, 107]],\n",
       "\n",
       "       [[ 94,  76,  75],\n",
       "        [123, 101, 105],\n",
       "        [169, 144, 145],\n",
       "        ...,\n",
       "        [152, 123, 120],\n",
       "        [133, 107, 101],\n",
       "        [168, 146, 137]],\n",
       "\n",
       "       [[133, 113, 110],\n",
       "        [151, 128, 130],\n",
       "        [147, 121, 120],\n",
       "        ...,\n",
       "        [167, 139, 133],\n",
       "        [164, 138, 130],\n",
       "        [197, 174, 168]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 87,  69,  74],\n",
       "        [102,  82,  85],\n",
       "        [ 97,  73,  75],\n",
       "        ...,\n",
       "        [175, 158, 152],\n",
       "        [143, 124, 121],\n",
       "        [158, 134, 130]],\n",
       "\n",
       "       [[ 87,  68,  69],\n",
       "        [100,  79,  79],\n",
       "        [110,  86,  84],\n",
       "        ...,\n",
       "        [148, 131, 123],\n",
       "        [160, 143, 143],\n",
       "        [172, 155, 157]],\n",
       "\n",
       "       [[ 93,  74,  71],\n",
       "        [157, 136, 131],\n",
       "        [170, 145, 139],\n",
       "        ...,\n",
       "        [164, 147, 136],\n",
       "        [164, 149, 151],\n",
       "        [189, 178, 185]]], dtype=uint8)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_element['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAHOCAYAAACSOG8/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA03klEQVR4nO3de5hkZXnv/e9PBoKIHJQOQYZxiCEo8VXwnRgVo0Q0AVRwvzlB4jFmT3JtUYwmBpNsRd8ciFGDRjR7IgYSCcYgRlRU2KibmChxQILASCSIMuPAjAeORgG99x+1xjRt93T1zOpeq2t9P9fVV1eteupZ91T3Pf2rVU/VSlUhSZIkDc0Dui5AkiRJ6oJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYEQJJPJvn1pb5vXyV5YJIPJrk9yT90XU9XkpyW5N2LMO9OPb5JViepJCua6x9J8oK265Q02QzC0oRJclOSp3ddx3RJfjzJPyT5WhN8rk7yiiS7LPJ+z07yhzt4918A9gceWlW/2GJZY0ny5CT/0jxe30jyz0l+cqnrWETzPr4L+b2pqmOr6pydLSrJC5N8amfnkbQ8GIQlLaokjwAuB24G/p+q2hv4RWAN8OAua5vHw4F/r6r7FnrHbUcpd1SSvYAPAX8BPAQ4EHgd8J2dmbdntvv4LuPfG0nLiEFYGogk+yb5UJKtSb7ZXF45Y9gjkvxrkjuSfCDJQ6bd/wnNEcrbkvxbkqPG3PXrgH+pqldU1WaAqrq+qn6lqm5r5j4+ybXN3J9M8qhp+60kPzbt+veP8iY5KsnGJK9MsiXJ5iQvam5bC/wq8KokdyX5YLP9d5NsSnJnkuuTHD3LY/U64DXALzf3fXGSByT5gyRfbvb1N0n2bsZve5n+xUm+Anx8Bx//bX68eZzOq6rvVtV/VtXFVXV1M9cjknw8ydebo6XnJtln2r5uSvI7zRHUu5OclWT/ZvnAnUn+d5J9Z9S+NslXm8fwt+f6YS7k9yDJo5qf523Nz/f4uR7fWe4+7+/NjH3db3lOkl9LsqF5rD+W5OHTbqskv5nki01tZ2bkUcBfAk9s6rqtGX9ckuuax27T9h4fScuLQVgajgcAf83oSNwq4D+Bt80Y83zg14ADgPuAtwIkORD4MPCHjI5Q/jbwviRTY+z36cD5c92Y5MeB84CXA1PARcAHk+w25r/rR4C9GR01fTFwZpJ9q2odcC7whqras6qeneRQ4GTgJ6vqwcDPATfNnLCqXgv8MfD3zX3PAl7YfP0M8KPAnvzg4/dU4FHNvDON8/hv8+/Ad5Ock+TYbaF1mgB/Ajys2d9BwGkzxvw88AxGofrZwEeA32P0GD8AeNmM8T8DHAL8LPC7mWV5zUJ+D5LsCnwQuBj4YeClwLlJDp3j8Z1pu78325PkhObf+v8x+vf+E6PfsemeBfwk8Bjgl4Cfq6oNwG8Cn27q2qcZexbwG83vzKOZ5YmOpOXJICwNRFV9vareV1Xfqqo7gT9iFNym+9uquqaq7gb+J/BLGa3HfC5wUVVdVFXfq6pLgPXAcWPs+qHA5u3c/svAh6vqkqq6F3gj8EDgSWP+0+4FXl9V91bVRcBdwKFzjP0u8EPAYUl2raqbquo/xtzPrwJvrqobq+ou4NXAibn/MojTquruqvrPmXce8/HfNvYO4MlAAX8FbE1yYZL9m9tvaB6v71TVVuDNs8z1F1V1a1VtYhQEL6+qz1XVt4H3A0fMGP+6pvbPMwrsJ81S2kJ+D57A6MnC6VV1T1V9nNFyj9nmnc18vzfb85vAn1TVhmbpxR8Dh08/KtzUdVtVfQX4BHD4dua7l9HvzF5V9c2qunIH65LUMwZhaSCS7JHkfzUv7d8BXAbsk/u/8ejmaZe/DOwK7MfoKOYvNi8j39a8ZPxkRkeO5/P1ecY9rNkXAFX1vaaOA8eYG+DrM9aZfotRAPsBVXUDoyPPpwFbkrwnycPG3M/96mwur2D0hq9tbmYOYz7+02vdUFUvrKqVjI5CPgw4o5lr/6b2Tc1c72b0c5ru1mmX/3OW6zMfo5k/+9kel4X8HjwMuLn5eU6fd+yf6xzzjuPhwFum1fgNRkfRp+/7lmmX5/ydafw8o7D/5ST/J8kTd7AuST1jEJaG45WMjpT+VFXtBTyl2Z5pYw6adnkVoyNhX2MUkv62qvaZ9vWgqjp9jP3+b0ZBYi5fZRRcRsUkaerY1Gz6FrDHtPE/MsY+t6kf2FD1d1X15GafBfzpmHPdr05Gj8993D9g/sD+phnn8Z9VVX0BOJtRIIbREc5i9CayvRgdqZ13nnnM/Nl/dZYxC/k9+CpwUJLpf2dW8V8/1/nM93uzPTczWsowvc4HVtW/jHHf2X5nPltVJzBa4vGPwHt3sC5JPWMQlibTrkl2n/a1gtE77f8TuC2jN8G9dpb7PTfJYUn2AF4PnF9V32V0xPHZSX4uyS7NnEdl7jd7Tfda4ElJ/izJjwAk+bEk727e4PVe4JlJjm7Wlb6S0acjbAstVwG/0uz3GOZYTjCHWxmt56XZ76FJnpbkh4BvN4/H9+a68wznAb+V5OAke/Jfa1zH/VSJcR7/bXU+MqM3AK5srh/EaEnBZ6bNdRdwe7Nu93fGrGF7/mdz1PongBcBfz/LmIX8HlzO6EnMq5LsmtGb6p4NvGfMeub7vdmevwRe3fxbSLJ3knE/Au9WYOW2NepJdkvyq0n2bpbu3MH4vzOSes4gLE2mixiFrm1fpzF6Wf2BjI7wfgb46Cz3+1tGRx5vAXaneUNVVd0MbHsD0lZGR9x+hzH+D2nW4D4RWA1cm+R24H2M1pbeWVXXMzqi+RdNbc8Gnl1V9zRTnNJsu43ROt1/HOcBaJzFaG3nbUn+kdH64NOb/dzC6Ajfq8ec612MHp/LgC8xCtIvXUAtZzD/47/NncBPAZcnubsZfw2jJwkw+kSFxwG3M3rz2gULqGMu/we4AbgUeGNVXTxzwEJ+D5qf37OBYxn9m98OPL85uj2v+X5v5rnv+xkd6X9Ps3TkmqaOcXwcuBa4JcnXmm3PA25q5vpNRr+HkiZAqrb3Sp4kaZIlWc0o2O+6I5+ZLEnLmUeEJUmSNEgGYUmSJA2SSyMkSZI0SB4RliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCdEktOSvLu5vCrJXUl26bouSbOzZ6Xlw36dXAbhZSTJryRZ3zTg5iQfSfLkmeOq6itVtWdVfbeFfX4yya/PM+bwJFck+Vbz/fCd3a80CXrcs+uSXJ/ke0leuLP7lCZBH/s1yY8n+UCSrUm+keRjSQ7d2f3qvxiEl4kkrwDOAP4Y2B9YBbwdOKHDskiyG/AB4N3AvsA5wAea7dJg9bVnG/8G/A/gyq4Lkfqgx/26D3AhcCijuv6V0d9ctcQgvAwk2Rt4PfCSqrqgqu6uqnur6oNV9TuzjF+dpJKs2Hb/JGc1z3A3JfnDbS/pJHlhkk8leWOSbyb5UpJjm9v+CPhp4G3NM+S3zVLeUcAK4Iyq+k5VvRUI8LTFeCyk5aDnPUtVnVlVlwLfXqSHQFo2+tyvVfWvVXVWVX2jqu4F/hw4NMlDF+8RGRaD8PLwRGB34P07eP+zgfuAHwOOAH4WmP5SzE8B1wP7AW8AzkqSqvp94J+Ak5uXgU6eZe6fAK6uqpq27epmuzRUfe5ZSfe3nPr1KcAtVfX1HaxVMxiEl4eHAl+rqvsWesck+wPHAS9vnuVuYfSM8sRpw75cVX/VrHc6BziA0Usw49gTuH3GttuBBy+0VmmC9LlnJd3fsujXJCuBM4FXLPS+mtuKrgvQWL4O7JdkxQ406sOBXYHNSbZtewBw87Qxt2y7UFXfasbtOeb8dwF7zdi2F3DnAuuUJkmfe1bS/fW+X5NMARcDb6+q8xZYo7bDI8LLw6eB7wDP2YH73tzcd7+q2qf52quqxl26UPPcfi3wmEz7HwB4TLNdGqo+96yk++t1vybZl1EIvrCq/mgHatR2GISXgaq6HXgNcGaS5yTZI8muSY5N8oZ57ruZUQO9KcleSR6Q5BFJnjrm7m8FfnQ7t38S+C7wsiQ/lGTbGqePjzm/NHF63rMk2S3J7oze2Lprkt2T+PdAg9Tnfk2yF/Ax4J+r6tQx59QC+B/fMlFVb2K0LugPgK2MnoWeDPzjGHd/PrAbcB3wTeB8RmuUxvEW4Bead7u+dZa67mH0LPr5wG3ArwHPabZLg9XXnm1cDPwn8CRgXXP5KWPOL02cHvfrfwN+EnhR88kS275WjTm/5pH7v9lfkiRJGgaPCEuSJGmQDMKSJEkaJIOwJEmSBskgLEmSpEHq7IQa++23X61evbqr3Uu9c8UVV3ytqqa6rmM29qt0f33uV7BnpZnm6tnOgvDq1atZv359V7uXeifJl7uuYS72q3R/fe5XsGelmebqWZdGSJIkaZAMwpIkSRokg7AkSZIGad4gnORdSbYkuWaO25PkrUluSHJ1kse1X6akcdmz0mRJcmiSq6Z93ZHk5V3XJU2CcY4Inw0cs53bjwUOab7WAu/Y+bIk7YSzsWeliVFV11fV4VV1OPD/At8C3t9tVdJkmDcIV9VlwDe2M+QE4G9q5DPAPkkOaKtASQtjz0oT7WjgP6qq159aIS0XbawRPhC4edr1jc02Sf1kz0rL14nAeV0XIU2KJf0c4SRrGb0Uy6pVq+Ydv/rUD7ey35tOf2Yr80hDstB+lbr2I5+4qpV5bvmZw1uZp21JdgOOB149x+32rJaVPvRsG0eENwEHTbu+stn2A6pqXVWtqao1U1O9PSGPNOnG6ln7VeqdY4Erq+rW2W60Z6WFayMIXwg8v3kn+hOA26tqcwvzSloc9qy0PJ2EyyKkVs27NCLJecBRwH5JNgKvBXYFqKq/BC4CjgNuYPRO1hctVrGS5mfPSpMnyYOAZwC/0XUt0iSZNwhX1Unz3F7AS1qrSNJOsWelyVNVdwMP7boOadJ4ZjlJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliRJ0iAZhCVJkjRIBmFJkiQNkkFYkiRJg2QQliSp55Lsk+T8JF9IsiHJE7uuSZoEK7ouQJIkzestwEer6heS7Abs0XVB0iQwCEuS1GNJ9gaeArwQoKruAe7psiZpUrg0QpKkfjsY2Ar8dZLPJXlnkgd1XZQ0CQzCkiT12wrgccA7quoI4G7g1JmDkqxNsj7J+q1bty51jdKyZBCWJKnfNgIbq+ry5vr5jILx/VTVuqpaU1VrpqamlrRAabkyCEuS1GNVdQtwc5JDm01HA9d1WJI0MXyznCRJ/fdS4NzmEyNuBF7UcT3SRDAIS5LUc1V1FbCm6zqkSePSCEmSJA3SWEE4yTFJrk9yQ5LZ3qm6Ksknmo91uTrJce2XKmkc9qskSeOZNwgn2QU4EzgWOAw4KclhM4b9AfDe5mNdTgTe3nahkuZnv0qSNL5xjgg/Hrihqm5szmbzHuCEGWMK2Ku5vDfw1fZKlLQA9qskSWMaJwgfCNw87frGZtt0pwHPTbIRuIjRu1t/gB/2LS06+1WSpDG19Wa5k4Czq2olcBzwt0l+YG4/7FvqBftVkiTGC8KbgIOmXV/ZbJvuxcB7Aarq08DuwH5tFChpQexXSZLGNE4Q/ixwSJKDmw/yPhG4cMaYrzA60w1JHsXoD6uvpUpLz36VJGlM8wbhqroPOBn4GLCB0bvNr03y+iTHN8NeCfz3JP8GnAe8sKpqsYqWNDv7VZKk8Y11ZrmquojRm2qmb3vNtMvXAUe2W5qkHWG/SpI0Hs8sJ0mSpEEyCEuSJGmQDMKSJEkaJIOwJEmSBskgLEmSpEEa61MjJElSd5LcBNwJfBe4r6rWdFuRNBkMwpIkLQ8/U1Vf67oIaZK4NEKSJEmDZBCWJKn/Crg4yRVJ1nZdjDQpXBohSVL/PbmqNiX5YeCSJF+oqsumD2gC8lqAVatWdVGjZnjTLz+rlXle+fcfamUe/SCPCEuS1HNVtan5vgV4P/D4Wcasq6o1VbVmampqqUuUliWDsCRJPZbkQUkevO0y8LPANd1WJU0Gl0ZIktRv+wPvTwKjv9t/V1Uf7bYkaTIYhCVJ6rGquhF4bNd1SJPIpRGSJEkaJIOwJEmSBskgLEmSpEEyCEuSJGmQDMKSJEkaJIOwJEmSBskgLEmSpEEyCEuSJGmQDMKSJEkaJIOwJEmSBmmsIJzkmCTXJ7khyalzjPmlJNcluTbJ37VbpqRx2a+SJI1nxXwDkuwCnAk8A9gIfDbJhVV13bQxhwCvBo6sqm8m+eHFKljS3OxXSZLGN84R4ccDN1TVjVV1D/Ae4IQZY/47cGZVfROgqra0W6akMdmvkiSNaZwgfCBw87TrG5tt0/048ONJ/jnJZ5IcM9tESdYmWZ9k/datW3esYknbY79KkjSmtt4stwI4BDgKOAn4qyT7zBxUVeuqak1VrZmammpp15IWyH6VlqEkuyT5XJIPdV2LNCnGCcKbgIOmXV/ZbJtuI3BhVd1bVV8C/p3RH1pJS8t+lSbXKcCGrouQJsk4QfizwCFJDk6yG3AicOGMMf/I6OgSSfZj9NLrje2VKWlM9qs0gZKsBJ4JvLPrWqRJMm8Qrqr7gJOBjzF6Jvreqro2yeuTHN8M+xjw9STXAZ8Afqeqvr5YRUuanf0qTawzgFcB3+u4DmmizPvxaQBVdRFw0Yxtr5l2uYBXNF+SOmS/SpMlybOALVV1RZKjtjNuLbAWYNWqVUtTnLTMeWY5SZL67Ujg+CQ3MfpIxKcleffMQb7BVVo4g7AkST1WVa+uqpVVtZrRuv+PV9VzOy5LmggGYUmSJA3SWGuEJUlS96rqk8AnOy5DmhgeEZYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJKkHkuye5J/TfJvSa5N8rqua5ImxYquC5AkSdv1HeBpVXVXkl2BTyX5SFV9puvCpOXOICxJUo9VVQF3NVd3bb6qu4qkyeHSCEmSei7JLkmuArYAl1TV5R2XJE0Eg7AkST1XVd+tqsOBlcDjkzx65pgka5OsT7J+69atS16jtByNFYSTHJPk+iQ3JDl1O+N+PkklWdNeiZIWwn6VJldV3QZ8AjhmltvWVdWaqlozNTW15LVJy9G8QTjJLsCZwLHAYcBJSQ6bZdyDgVMAX66ROmK/SpMnyVSSfZrLDwSeAXyh06KkCTHOEeHHAzdU1Y1VdQ/wHuCEWcb9/8CfAt9usT5JC2O/SpPnAOATSa4GPstojfCHOq5JmgjjBOEDgZunXd/YbPu+JI8DDqqqD29vItcvSYvOfpUmTFVdXVVHVNVjqurRVfX6rmuSJsVOv1kuyQOANwOvnG+s65ekbtmvkiT9l3GC8CbgoGnXVzbbtnkw8Gjgk0luAp4AXOgbcKRO2K+SJI1pnCD8WeCQJAcn2Q04Ebhw241VdXtV7VdVq6tqNfAZ4PiqWr8oFUvaHvtVkqQxzRuEq+o+4GTgY8AG4L1VdW2S1yc5frELlDQ++1WSpPGNdYrlqroIuGjGttfMMfaonS9L0o6yXyVJGo9nlpMkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSeqxJAcl+USS65Jcm+SUrmuSJsVYp1iWJEmduQ94ZVVdmeTBwBVJLqmq67ouTFruPCIsSVKPVdXmqrqyuXwnsAE4sNuqpMlgEJYkaZlIsho4Ari841KkieDSCEmSloEkewLvA15eVXfMcvtaYC3AqlWr5p1v9akfbqWum05/ZivzSF3wiLAkST2XZFdGIfjcqrpgtjFVta6q1lTVmqmpqaUtUFqmDMKSJPVYkgBnARuq6s1d1yNNEoOwJEn9diTwPOBpSa5qvo7ruihpErhGWJKkHquqTwHpug5pEnlEWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgjRWEkxyT5PokNyQ5dZbbX5HkuiRXJ7k0ycPbL1XSOOxXSZLGM28QTrILcCZwLHAYcFKSw2YM+xywpqoeA5wPvKHtQiXNz36VJGl84xwRfjxwQ1XdWFX3AO8BTpg+oKo+UVXfaq5+BljZbpmSxmS/SpI0pnGC8IHAzdOub2y2zeXFwEdmuyHJ2iTrk6zfunXr+FVKGpf9KknSmFp9s1yS5wJrgD+b7faqWldVa6pqzdTUVJu7lrRA9qskaehWjDFmE3DQtOsrm233k+TpwO8DT62q77RTnqQFsl8lSRrTOEeEPwsckuTgJLsBJwIXTh+Q5AjgfwHHV9WW9suUNCb7VZKkMc0bhKvqPuBk4GPABuC9VXVtktcnOb4Z9mfAnsA/JLkqyYVzTCdpEdmvkiSNb5ylEVTVRcBFM7a9Ztrlp7dcl6QdZL9KkjQezywnSVKPJXlXki1Jrum6FmnSGIQlSeq3s4Fjui5CmkQGYUmSeqyqLgO+0XUd0iQyCEuSJGmQDMKSJE0AzwYpLZxBWJKkCeDZIKWFMwhLkiRpkAzCkiT1WJLzgE8DhybZmOTFXdckTYqxTqghSZK6UVUndV2DNKk8IixJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGqSxgnCSY5Jcn+SGJKfOcvsPJfn75vbLk6xuvVJJY7FfpckzX19L2jHzBuEkuwBnAscChwEnJTlsxrAXA9+sqh8D/hz407YLlTQ/+1WaPGP2taQdMM4R4ccDN1TVjVV1D/Ae4IQZY04Azmkunw8cnSTtlSlpTParNHnG6WtJO2DFGGMOBG6edn0j8FNzjamq+5LcDjwU+Nr0QUnWAmubq3cluX6efe83c44dkfaOd7VST4v6VE+faoHlWc/DW9jPsu/XFlnP9lnPHLJ0/Tqucfp6uf+N7c3Pv9Gren77velVPfTs8dmZnh0nCLemqtYB68Ydn2R9Va1ZxJIWxHrm1qdawHraYL+2y3q2r0/19KmWhVjOPdunWsB65jNJ9YyzNGITcNC06yubbbOOSbIC2Bv4+o4UJGmn2K/S5BmnryXtgHGC8GeBQ5IcnGQ34ETgwhljLgRe0Fz+BeDjVVXtlSlpTParNHnG6WtJO2DepRHNGsKTgY8BuwDvqqprk7weWF9VFwJnAX+b5AbgG4yatA1jv8SzRKxnbn2qBQZaj/16P9azfdYztz7VMmdftzB1n/6dfaoFrGc+E1NPPBAkSZKkIfLMcpIkSRokg7AkSZIGqbdBuC+nk0xyUJJPJLkuybVJTumqlumS7JLkc0k+1INa9klyfpIvJNmQ5Ikd1/Nbzc/qmiTnJdl9iff/riRbklwzbdtDklyS5IvN932XsqbF1pd+bWrpXc/ar9utx35dYvbr/OzZOWvptF+bGlrt2V4G4fTrdJL3Aa+sqsOAJwAv6bCW6U4BNnRdROMtwEer6pHAY+mwriQHAi8D1lTVoxm9saStN4ON62zgmBnbTgUurapDgEub6xOhZ/0K/exZ+3UW9uvSs1/HZs/O0JN+hZZ7tpdBmB6dTrKqNlfVlc3lOxn9Ah7YRS3bJFkJPBN4Z5d1NLXsDTyF0ScRUFX3VNVtnRY1+jSUBzafkbsH8NWl3HlVXcbo0ximm35a43OA5yxlTYusN/0K/etZ+3Ve9uvSsl/nYc9uV6f9Cu33bF+D8Gynk+y0MQCSrAaOAC7vuJQzgFcB3+u4DoCDga3AXzcvI70zyYO6KqaqNgFvBL4CbAZur6qLu6pnmv2ranNz+RZg/y6LaVkv+xV607NnYL/Oyn7thP06vzOwZ39Aj/sVdqJn+xqEeyfJnsD7gJdX1R0d1vEsYEtVXdFVDTOsAB4HvKOqjgDupsOXEZt1QScw+s/jYcCDkjy3q3pm05y8ws8tXGR96Fn7dfvsV23Th35t6rBn57Ac+hUW3rN9DcK9Op1kkl0ZNei5VXVBV3U0jgSOT3ITo5e0npbk3R3WsxHYWFXbnsGfz6hpu/J04EtVtbWq7gUuAJ7UYT3b3JrkAIDm+5aO62lTr/oVetWz9uv22a9Lz37dPnt2bn3tV9iJnu1rEO7N6SSThNHanA1V9eYuapiuql5dVSurajWjx+XjVdXZM7KqugW4Ocmhzaajgeu6qofRSzZPSLJH87M7mn684WH6aY1fAHygw1ra1pt+hX71rP06L/t16dmv22HPbldf+xV2omfnPcVyFxbxdJI74kjgecDnk1zVbPu9qrqoo3r66KXAuc1/qjcCL+qqkKq6PMn5wJWM3o38OZb4VJBJzgOOAvZLshF4LXA68N4kLwa+DPzSUta0mHrWr2DPzsd+ncZ+tV+XgV70bB/6FdrvWU+xLEmSpEHq69IISZIkaVEZhCVJkjRIBuEJkeS0be9sTbIqyV3NGYQk9ZA9Ky0f9uvkMggvI0l+Jcn6pgE3J/lIkifPHFdVX6mqPavquy3s85NJfn07t++X5J+TfD3JbUk+neTInd2vNAn62LMzxj4/SY07Xppkfe3Xpkfvbuq6K0nnZ7ybJAbhZSLJKxid7eaPGZ0xZRXwdjo8NWbjLuDXgClgX+BPgQ9mdPpFabB63LPA9z8c//eALj8xQOqFvvcr8NgmfO9ZVT5xbZFBeBnI6FzjrwdeUlUXVNXdVXVvVX2wqn5nlvGrm2eQK7bdP8lZzTPcTUn+cNtLOklemORTSd6Y5JtJvpTk2Oa2PwJ+Gnhb8yz0bTP3VVXfrqrrq+p7QIDvMgrED1msx0Pquz737DR/ArwV+FrL/3xpWVkm/apFYhBeHp4I7A68fwfvfzajz/z7MUbncf9ZYPozyp8Crgf2A94AnJUkVfX7wD8BJzfPQk+eawdJrga+zehDrd9ZVZN0JiZpoXrds0keD6wB/nIH65MmSa/7tXFZkluSXJBk9Q7WqVkYhJeHhwJfq6r7FnrHJPsDxzE6f/vdTUD9c0ZnzNnmy1X1V816p3OAAxi9NDS2qnoMsBfwK8CnFlqnNGF627PNkaq3M/rj+72F1idNoN72a+OpwGrgkcBXgQ+5/LA9PpDLw9cZnUFlxQ406sOBXYHNSbZtewBw87Qxt2y7UFXfasbtudAiq+rbwHlJNiS5qqr+baFzSBOizz37P4Crq+ozC6xLmlR97leq6rLm4j1JTgHuAB4FfH6BtWoWBuHl4dPAd4DnAOcv8L43N/fdb0ee7QI7curBXYEfBQzCGqo+9+zRwFOTHNdcfwhwRJLD53lpVppUfe7Xue6TeUdpLC6NWAaq6nbgNcCZSZ6TZI8kuyY5Nskb5rnvZuBi4E1J9krygCSPSPLUMXd/K6NQO6skT0jy5CS7JXlgkt9l9JLP5WPOL02cPvcs8EJGR5MOb77WA68Dfn/M+aWJ0ud+TfITSQ5PskuSPYE3AZuADWPOr3kYhJeJqnoT8ArgD4CtjJ6Fngz84xh3fz6wG3Ad8E1Gz3gPGHPXbwF+oXm361tnuf2HgDMZvbS0idFaqWdW1VfHnF+aSH3t2aq6rapu2fYF3APc0YQBaZD62q+MDiz9PaPlEDcyWiv8rKq6d8z5NY9U7chReUmSJGl584iwJEmSBskgLEmSpEEyCEuSJGmQDMKSJEkaJIOwJEmSBqmzE2rst99+tXr16q52L/XOFVdc8bWqmuq6jtnYr9L99blfwZ6VZpqrZzsLwqtXr2b9+vVd7V7qnSRf7rqGudiv0v31uV/BnpVmmqtnXRohSZKkQTIIS5IkaZAWFISTvCvJliTXTNv2Z0m+kOTqJO9Psk/rVUpqXZLfSnJtkmuSnJdk965rkoYsyUFJPpHkuqY3T2m2PyTJJUm+2Hzft+tapUmx0CPCZwPHzNh2CfDoqnoM8O/Aq1uoS9IiSnIg8DJgTVU9GtgFOLHbqqTBuw94ZVUdBjwBeEmSw4BTgUur6hDg0ua6pBYsKAhX1WXAN2Zsu7iq7muufgZY2VJtkhbXCuCBSVYAewBf7bgeadCqanNVXdlcvhPYABwInACc0ww7B3hOJwVKE6jtNcK/Bnyk5TkltayqNgFvBL4CbAZur6qLu61K0jZJVgNHAJcD+1fV5uamW4D9u6pLmjStfXxakt9n9LLOudsZsxZYC7Bq1aq2dq0Jctppp/VqnknVrDE8ATgYuA34hyTPrap3TxtjvwIbHvmoVuZ51Bc2tDJP39iz7UuyJ/A+4OVVdUeS799WVZWk5rifPTuhNp76T63Ms/L0n25lnknSyhHhJC8EngX8alXN2qAAVbWuqtZU1Zqpqd5+Drk0BE8HvlRVW6vqXuAC4EnTB9iv0tJLsiujEHxuVV3QbL41yQHN7QcAW2a7rz0rLdxOB+EkxwCvAo6vqm/tfEmSlsBXgCck2SOjw01HM1qPKKkjTS+eBWyoqjdPu+lC4AXN5RcAH1jq2qRJtdCPTzsP+DRwaJKNSV4MvA14MHBJkquS/OUi1CmpRVV1OXA+cCXweUb/F6zrtChJRwLPA57W/D29KslxwOnAM5J8kdGrOad3WaQ0SRa0RriqTppl81kt1SJpCVXVa4HXdl2HpJGq+hSQOW4+eilrkYbCM8tJkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgZpwUE4ybuSbElyzbRtD0lySZIvNt/3bbdMSZIkqV07ckT4bOCYGdtOBS6tqkOAS5vrkiRJUm8tOAhX1WXAN2ZsPgE4p7l8DvCcnStLkiRJWlxtrRHev6o2N5dvAfZvaV5JkiRpUbT+ZrmqKqBmuy3J2iTrk6zfunVr27uWJEmSxtZWEL41yQEAzfctsw2qqnVVtaaq1kxNTbW0a0mSJGnh2grCFwIvaC6/APhAS/NKkiRJi2JHPj7tPODTwKFJNiZ5MXA68IwkXwSe3lyXJEmSemvFQu9QVSfNcdPRO1mLJEmStGQWHIQlSZK0/Jx22mm9mqcPPMWyJEmSBskgLEmSpEEyCEuSJGmQDMKSJEkaJIOwNFBJ9klyfpIvJNmQ5Ild1yQNWZJ3JdmS5Jpp205LsinJVc3XcV3WKE0ag7A0XG8BPlpVjwQeC2zouB5p6M4Gjpll+59X1eHN10VLXJM00QzC0gAl2Rt4CnAWQFXdU1W3dVqUNHBVdRnwja7rkIbEICwN08HAVuCvk3wuyTuTPGj6gCRrk6xPsn7r1q3dVCkJ4OQkVzdLJ/ada5A9Ky2cQVgaphXA44B3VNURwN3AqdMHVNW6qlpTVWumpqa6qFESvAN4BHA4sBl401wD7Vlp4QzC0jBtBDZW1eXN9fMZBWNJPVJVt1bVd6vqe8BfAY/vuiZpkhiEpQGqqluAm5Mc2mw6Griuw5IkzSLJAdOu/jfgmrnGSlq4FV0XIKkzLwXOTbIbcCPwoo7rkQYtyXnAUcB+STYCrwWOSnI4UMBNwG90VZ80iQzC0kBV1VXAmq7rkDRSVSfNsvmsJS9EGhCXRkiSJGmQDMKSJEkaJIOwJEmSBskgLEmSpEFqLQgn+a0k1ya5Jsl5SXZva25JkiSpba0E4SQHAi8D1lTVo4FdgBPbmFuSJElaDG0ujVgBPDDJCmAP4Kstzi1JkiS1qpUgXFWbgDcCX2F0LvTbq+riNuaWJEmSFkNbSyP2BU4ADgYeBjwoyXNnGbc2yfok67du3drGriVJkqQd0tbSiKcDX6qqrVV1L3AB8KSZg6pqXVWtqao1U1NTLe1akiRJWri2gvBXgCck2SNJgKOBDS3NLUmSJLWurTXClwPnA1cCn2/mXdfG3JIkSdJiWNHWRFX1WuC1bc0nSZIkLSbPLCdJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGqTWgnCSfZKcn+QLSTYkeWJbc0taHEl2SfK5JB/quhZp6JK8K8mWJNdM2/aQJJck+WLzfd8ua5QmTZtHhN8CfLSqHgk8FtjQ4tySFscp2KtSX5wNHDNj26nApVV1CHBpc11SS1oJwkn2Bp4CnAVQVfdU1W1tzC1pcSRZCTwTeGfXtUiCqroM+MaMzScA5zSXzwGes5Q1SZNuRUvzHAxsBf46yWOBK4BTquru6YOSrAXWAqxataqlXUs/6NKPP6KVeY5+2n+0Mk9PnQG8CnjwbDfar1Iv7F9Vm5vLtwD7zzXQnpUWrq2lESuAxwHvqKojgLuZ5eWbqlpXVWuqas3U1FRLu5a0UEmeBWypqivmGmO/Sv1SVQXUdm63Z6UFaisIbwQ2VtXlzfXzGQVjSf10JHB8kpuA9wBPS/LubkuSNItbkxwA0Hzf0nE90kRpJQhX1S3AzUkObTYdDVzXxtyS2ldVr66qlVW1GjgR+HhVPbfjsiT9oAuBFzSXXwB8oMNapInT1hphgJcC5ybZDbgReFGLc0uSNNGSnAccBeyXZCPwWuB04L1JXgx8Gfil7iqUJk9rQbiqrgLWtDWfpKVRVZ8EPtlxGdLgVdVJc9x09JIWIg2IZ5aTJEnSIBmEJUmSNEgGYUmSJA2SQViSJEmDZBCWJEnSIBmEJUmSNEgGYUmSJA2SQViSJEmD1OaZ5TRgG0/9p3Ym2r2daSRJkubjEWFJkiQNkkFYkiRJg+TSCEmSBmj1qR9uZZ6bTn9mK/NIXfCIsCRJkgbJICxJkqRBMghLkiRpkFwjLEkD5EceSpJHhCVJkjRQBmFJkiQNUqtBOMkuST6X5ENtzitJkiS1re0jwqcAG1qeU5IkSWpda0E4yUrgmcA725pTkiRJWixtHhE+A3gV8L0W55QkSZIWRStBOMmzgC1VdcU849YmWZ9k/datW9vYtSRJkrRD2joifCRwfJKbgPcAT0vy7pmDqmpdVa2pqjVTU1Mt7VqSJElauFaCcFW9uqpWVtVq4ETg41X13DbmliRJkhaDnyMsSZKkQWr9FMtV9Ungk23PK0mSJLXJI8KSJEkaJIOwJEmSBskgLEmSpEEyCEuSJGmQDMKSJEkapNY/NUJS/yU5CPgbYH+ggHVV9ZZuq5I0l+aEVXcC3wXuq6o13VYkTQaDsDRM9wGvrKorkzwYuCLJJVV1XdeFSZrTz1TV17ouQpokLo2QBqiqNlfVlc3lO4ENwIHdViVJ0tIyCEsDl2Q1cARwecelSJpbARcnuSLJ2q6LkSaFSyOkAUuyJ/A+4OVVdceM29YCawFWrVrVQXWSpnlyVW1K8sPAJUm+UFWXTR9gz0oL5xFhaaCS7MooBJ9bVRfMvL2q1lXVmqpaMzU1tfQFSvq+qtrUfN8CvB94/Cxj7FlpgQzC0gAlCXAWsKGq3tx1PZLmluRBzZtaSfIg4GeBa7qtSpoMLo2QhulI4HnA55Nc1Wz7vaq6qLuSJM1hf+D9o+evrAD+rqo+2m1J0mQwCEsDVFWfAtJ1HZLmV1U3Ao/tug5pErk0QpIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYPUShBOclCSTyS5Lsm1SU5pY15JkiRpsbT18Wn3Aa+sqiubD/2+IsklVXVdS/NLkiRJrWrliHBVba6qK5vLdwIbgAPbmFuSJElaDK2fUCPJauAI4PJZblsLrAVYtWrVvHOtPvXDrdR00+nPbGUeSZIkTY5W3yyXZE/gfcDLq+qOmbdX1bqqWlNVa6amptrctSRJkrQgrQXhJLsyCsHnVtUFbc0rSZIkLYa2PjUiwFnAhqp6cxtzSpIkSYuprSPCRwLPA56W5Krm67iW5pYkSZJa18qb5arqU0DamEuSJElaCp5ZTpIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgGYQlSZI0SAZhSZIkDZJBWJIkSYNkEJYkSdIgtRaEkxyT5PokNyQ5ta15JS0Oe1ZaPuxXaXG0EoST7AKcCRwLHAaclOSwNuaW1D57Vlo+7Fdp8bR1RPjxwA1VdWNV3QO8Bzihpbkltc+elZYP+1VaJG0F4QOBm6dd39hsk9RP9qy0fNiv0iJZsZQ7S7IWWNtcvSvJ9fPcZT/gazu93z/d2Rm+r5V6WtSnevpUC7RWT3Z+ipFx6nl4WztrQ1f92qJ+1ZP0q56ePT6ve93r+lTPsutXWPZ/Y/v08wfr2a6e9SvsRM+2FYQ3AQdNu76y2XY/VbUOWDfupEnWV9WanS+vHdYztz7VAtYzhnl71n5tl/VsX5/q6VMtjYn/G9unWsB65jNJ9bS1NOKzwCFJDk6yG3AicGFLc0tqnz0rLR/2q7RIWjkiXFX3JTkZ+BiwC/Cuqrq2jbkltc+elZYP+1VaPK2tEa6qi4CL2pqvMfZLPEvEeubWp1rAeua1CD3bt3+j9Wyf9cytT7UAg/gb26dawHrmMzH1pKraLESSJElaFjzFsiRJkgapt0G4L6eTTHJQkk8kuS7JtUlO6aqW6ZLskuRzST7Ug1r2SXJ+ki8k2ZDkiR3X81vNz+qaJOcl2X2J9/+uJFuSXDNt20OSXJLki833fZeypsXWl35tauldz9qv263Hfl1i9uv87Nk5a+m0X5saWu3ZXgbh9Ot0kvcBr6yqw4AnAC/psJbpTgE2dF1E4y3AR6vqkcBj6bCuJAcCLwPWVNWjGb2x5MQlLuNs4JgZ204FLq2qQ4BLm+sToWf9Cv3sWft1Fvbr0rNfx2bPztCTfoWWe7aXQZgenU6yqjZX1ZXN5TsZ/QJ2ekafJCuBZwLv7LKOppa9gacAZwFU1T1VdVunRY3eBPrAJCuAPYCvLuXOq+oy4BszNp8AnNNcPgd4zlLWtMh606/Qv561X+dlvy4t+3Ue9ux2ddqv0H7P9jUI9/J0kklWA0cAl3dcyhnAq4DvdVwHwMHAVuCvm5eR3pnkQV0VU1WbgDcCXwE2A7dX1cVd1TPN/lW1ubl8C7B/l8W0rJf9Cr3p2TOwX2dlv3bCfp3fGdizP6DH/Qo70bN9DcK9k2RP4H3Ay6vqjg7reBawpaqu6KqGGVYAjwPeUVVHAHfT4cuIzbqgExj95/Ew4EFJnttVPbOp0Ue1+HEti6wPPWu/bp/9qm360K9NHfbsHJZDv8LCe7avQXis00kulSS7MmrQc6vqgq7qaBwJHJ/kJkYvaT0tybs7rGcjsLGqtj2DP59R03bl6cCXqmprVd0LXAA8qcN6trk1yQEAzfctHdfTpl71K/SqZ+3X7bNfl579un327Nz62q+wEz3b1yDcm9NJJgmjtTkbqurNXdQwXVW9uqpWVtVqRo/Lx6uqs2dkVXULcHOSQ5tNRwPXdVUPo5dsnpBkj+ZndzT9eMPDhcALmssvAD7QYS1t602/Qr961n6dl/269OzX7bBnt6uv/Qo70bOtnVmuTT07neSRwPOAzye5qtn2e81ZfjTyUuDc5j/VG4EXdVVIVV2e5HzgSkbvRv4cS3wGnCTnAUcB+yXZCLwWOB14b5IXA18Gfmkpa1pMPetXsGfnY79OY7/ar8tAL3q2D/0K7fesZ5aTJEnSIPV1aYQkSZK0qAzCkiRJGiSDsCRJkgbJICxJkqRBMghLkiRpkAzCkiRJGiSDsCRJkgbJICxJkqRB+r/Egj7w6LZPkAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x504 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution of Data among the 6 Clients \n",
    "f = plt.figure(figsize=(12, 7))\n",
    "f.suptitle('Label Counts for a Sample of Clients')\n",
    "for i in range(6):\n",
    "  client_dataset = cifar_train.create_tf_dataset_for_client(\n",
    "      cifar_train.client_ids[i])\n",
    "  plot_data = collections.defaultdict(list)\n",
    "  for example in client_dataset:\n",
    "    # Append counts individually per label to make plots\n",
    "    # more colorful instead of one color per plot.\n",
    "    label = example['label'].numpy()\n",
    "    plot_data[label].append(label)\n",
    "  plt.subplot(2, 3, i+1)\n",
    "  plt.title('Client {}'.format(i))\n",
    "  for j in range(10):\n",
    "    plt.hist(\n",
    "        plot_data[j],\n",
    "        density=False,\n",
    "        bins=[0,1,2,3,4,5,6,7,8,9,10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to use with keras model\n",
    "def reshape_cifar_element(element):\n",
    " \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    " x=tf.reshape(element['image'], [-1, 3072])\n",
    " x=tf.cast(x,dtype=tf.float32)\n",
    " x /= 255\n",
    " y=tf.reshape(element['coarse_label'], [-1, 1])\n",
    " return collections.OrderedDict( \n",
    "    x=(tf.cast(tf.reshape(element['image'], [-1, 3072]),dtype=tf.float32))/255,\n",
    "    y=tf.reshape(element['label'], [-1, 1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Federated preprocessing that will drive the client training\n",
    "# load from the Inputted parameters \n",
    "def preprocess_dataset(dataset):\n",
    "  return (dataset\n",
    "          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)\n",
    "          .repeat(CLIENT_EPOCHS_PER_ROUND)\n",
    "          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)\n",
    "          .map(reshape_cifar_element)\n",
    "          .prefetch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              array([[0.80784315, 0.9607843 , 0.9764706 , ..., 0.28235295, 0.29411766,\n",
       "                      0.20784314],\n",
       "                     [0.58431375, 0.7882353 , 0.98039216, ..., 0.5568628 , 0.37254903,\n",
       "                      0.24313726],\n",
       "                     [0.27450982, 0.34509805, 0.08235294, ..., 0.44313726, 0.5019608 ,\n",
       "                      0.19607843],\n",
       "                     ...,\n",
       "                     [0.2509804 , 0.2509804 , 0.2509804 , ..., 0.3254902 , 0.3254902 ,\n",
       "                      0.3254902 ],\n",
       "                     [0.7176471 , 0.7764706 , 0.8666667 , ..., 0.46666667, 0.47058824,\n",
       "                      0.5058824 ],\n",
       "                     [0.49411765, 0.54509807, 0.5529412 , ..., 0.59607846, 0.5058824 ,\n",
       "                      0.4862745 ]], dtype=float32)),\n",
       "             ('y',\n",
       "              array([[71],\n",
       "                     [49],\n",
       "                     [93],\n",
       "                     [71],\n",
       "                     [33],\n",
       "                     [29],\n",
       "                     [71],\n",
       "                     [63],\n",
       "                     [34],\n",
       "                     [49],\n",
       "                     [93],\n",
       "                     [60],\n",
       "                     [33],\n",
       "                     [23],\n",
       "                     [99],\n",
       "                     [93],\n",
       "                     [23],\n",
       "                     [99],\n",
       "                     [71],\n",
       "                     [44]], dtype=int64))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks on examples data \n",
    "preprocessed_example_dataset = preprocess_dataset(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "sample_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to iterate over clients and preprocess.\n",
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess_dataset(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 2\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 3072)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int64)])>\n"
     ]
    }
   ],
   "source": [
    "# Build Federated data as per the input parameters \n",
    "sample_clients = cifar_train.client_ids[0:NUMBER_OF_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(cifar_train, sample_clients)\n",
    "\n",
    "print(f'Number of client datasets: {len(federated_train_data)}')\n",
    "print(f'First dataset: {federated_train_data[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100))\n",
    "\n",
    "\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model=create_original_fedavg_cnn_model()\n",
    "Model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 936,580\n",
      "Trainable params: 936,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the keras Model to be used in TFF\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  return tff.learning.from_keras_model(\n",
    "      Model,\n",
    "      input_spec= preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Variable and Metric Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare custom variables and Model metrics \n",
    "# Trainable Variable : Weights and biases of CNN\n",
    "# Model Metrics : Loss, Accuracy and number of examples to derive weighted average\n",
    "cifar100Variables = collections.namedtuple('cifar100Variables','weights bias num_examples loss_sum accuracy_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function defines the variables and metrics \n",
    "def create_cifar100_variables():\n",
    "    return cifar100Variables(\n",
    "      weights=tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(3072,100)),\n",
    "          name='weights',\n",
    "          trainable=True),\n",
    "      bias=tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(100)),\n",
    "          name='bias',\n",
    "          trainable=True),\n",
    "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
    "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
    "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform operation on Batch of Data\n",
    "# Build Forward pass\n",
    "def batch_model(variables,x):\n",
    "    # since the last step in the keras model is Activation, we aply the same to the weights and biases\n",
    "    return tf.nn.softmax(tf.matmul(x, variables.weights) + variables.bias)\n",
    "  \n",
    "# Define how forward pass will process metrics     \n",
    "def cifar100_forward_pass(variables, batch):\n",
    "  y = batch_model(variables, batch['x'])\n",
    "  predictions = tf.cast(tf.argmax(y, 1), tf.int64)\n",
    "\n",
    "  flat_labels = tf.reshape(batch['y'], [-1])\n",
    "  loss = -tf.reduce_mean(\n",
    "      tf.reduce_sum(tf.one_hot(flat_labels, 100) * tf.math.log(y), axis=[1]))\n",
    "  accuracy = tf.reduce_mean(\n",
    "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
    "\n",
    "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
    "\n",
    "  variables.num_examples.assign_add(num_examples)\n",
    "  variables.loss_sum.assign_add(loss * num_examples)\n",
    "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
    "\n",
    "  return loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return metrics from each model\n",
    "def get_local_unfinalized_metrics(variables):\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=[variables.num_examples],\n",
    "      loss=[variables.loss_sum, variables.num_examples],\n",
    "      accuracy=[variables.accuracy_sum, variables.num_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize metrics after training on all Clients \n",
    "def get_metric_finalizers():\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=tf.function(func=lambda x: x[0]),\n",
    "      loss=tf.function(func=lambda x: x[0] / x[1]),\n",
    "      accuracy=tf.function(func=lambda x: x[0] / x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Weighted Values\n",
    "def get_local_cifar_metrics(variables):\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=variables.num_examples,\n",
    "      loss=variables.loss_sum / variables.num_examples,\n",
    "      accuracy=variables.accuracy_sum / variables.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Metrics across all clients \n",
    "@tff.federated_computation\n",
    "def aggregate_cifar_metrics_across_clients(metrics):\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=tff.federated_sum(metrics.num_examples),\n",
    "      loss=tff.federated_mean(metrics.loss, metrics.num_examples),\n",
    "      accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Class declaration for TFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, OrderedDict\n",
    "\n",
    "class cifar100Model(tff.learning.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._variables = create_cifar100_variables()\n",
    "\n",
    "  @property\n",
    "  def trainable_variables(self):\n",
    "    return [self._variables.weights, self._variables.bias]\n",
    "\n",
    "  @property\n",
    "  def non_trainable_variables(self):\n",
    "    return []\n",
    "\n",
    "  @property\n",
    "  def local_variables(self):\n",
    "    return [\n",
    "        self._variables.num_examples, self._variables.loss_sum,\n",
    "        self._variables.accuracy_sum\n",
    "    ]\n",
    "\n",
    "  @property\n",
    "  def input_spec(self):\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.TensorSpec([None, 3072], tf.float32),\n",
    "        y=tf.TensorSpec([None, 1], tf.int64))\n",
    "\n",
    "  @tf.function\n",
    "  def predict_on_batch(self, x, training=True):\n",
    "    del training\n",
    "    return batch_model(self._variables, x)\n",
    "    \n",
    "  @tf.function\n",
    "  def forward_pass(self, batch, training=True):\n",
    "    del training\n",
    "    loss, predictions = cifar100_forward_pass(self._variables, batch)\n",
    "    num_examples = tf.shape(batch['x'])[0]\n",
    "    return tff.learning.BatchOutput(\n",
    "        loss=loss, predictions=predictions, num_examples=num_examples)\n",
    "        \n",
    "  @tf.function\n",
    "  def report_local_outputs(self):\n",
    "    return get_local_cifar_metrics(self._variables)\n",
    "\n",
    "  @property\n",
    "  def federated_output_computation(self):\n",
    "    return aggregate_cifar_metrics_across_clients\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def report_local_unfinalized_metrics(\n",
    "      self) -> OrderedDict[str, List[tf.Tensor]]:\n",
    "    \"\"\"Creates an `OrderedDict` of metric names to unfinalized values.\"\"\"\n",
    "    return get_local_unfinalized_metrics(self._variables)\n",
    "\n",
    "  def metric_finalizers(\n",
    "      self) -> OrderedDict[str, Callable[[List[tf.Tensor]], tf.Tensor]]:\n",
    "    \"\"\"Creates an `OrderedDict` of metric names to finalizers.\"\"\"\n",
    "    return get_metric_finalizers()\n",
    "\n",
    "  @tf.function\n",
    "  def reset_metrics(self):\n",
    "    \"\"\"Resets metrics variables to initial value.\"\"\"\n",
    "    for var in self.local_variables:\n",
    "      var.assign(tf.zeros_like(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model \n",
    "# no need for optimization on server as we are analyzing client learning\n",
    "federated_averaging = tff.learning.build_federated_averaging_process(\n",
    "    model_fn=cifar100Model,\n",
    "    client_optimizer_fn= lambda: tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    # server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=5.0)\n",
    "    # use_experimental_simulation_loop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Tensorboard Initialization\n",
    "import shutil\n",
    "import datetime\n",
    "run_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "hp = str\n",
    "logdir = r\"C:\\Users\\sidha\\Stevens\\AAI800 - Special Projects in AI\\Project Execution\\Tensorboard\\TF-CNN3\" + run_time + hyperparameters\n",
    "if os.path.exists(logdir):\n",
    "    shutil.rmtree(logdir)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Iterative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = federated_averaging.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.939502), ('accuracy', 0.04)]))])\n",
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.6244953), ('accuracy', 0.08)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.4307578), ('accuracy', 0.12)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.3220801), ('accuracy', 0.115)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.2279632), ('accuracy', 0.115)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.2010534), ('accuracy', 0.1)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.1649823), ('accuracy', 0.185)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.3883674), ('accuracy', 0.12)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.3514624), ('accuracy', 0.225)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('num_examples', 200.0), ('loss', 3.210318), ('accuracy', 0.22)]))])\n"
     ]
    }
   ],
   "source": [
    "with summary_writer.as_default():\n",
    "    for round_num in range(0, NUMBER_OF_ROUNDS):\n",
    "        state, metrics = federated_averaging.next(state, federated_train_data)\n",
    "            # result = iterative_process.next(state, federated_train_data)\n",
    "            # state = result.state\n",
    "            # metrics = result.metrics\n",
    "        print('round {:2d}, metrics={}'.format(round_num,metrics))\n",
    "        for name, value in metrics['train'].items():\n",
    "          tf.summary.scalar(name, value, step=round_num)\n",
    "        summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%##############################################\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Evaluation on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<\n",
      "  server_model_weights=<\n",
      "    trainable=<\n",
      "      float32[3072,100],\n",
      "      float32[100]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >@SERVER,\n",
      "  federated_dataset={<\n",
      "    x=float32[?,3072],\n",
      "    y=int64[?,1]\n",
      "  >*}@CLIENTS\n",
      "> -> <\n",
      "  num_examples=float32@SERVER,\n",
      "  loss=float32@SERVER,\n",
      "  accuracy=float32@SERVER\n",
      ">)\n"
     ]
    }
   ],
   "source": [
    "#inspect the abstract type signature of the evaluation function\n",
    "evaluation = tff.learning.build_federated_evaluation(cifar100Model)\n",
    "print(evaluation.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_federated.python.learning.model_utils.ModelWeights"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull final Model wights from training \n",
    "model_weights = tff.learning.ModelWeights(trainable=state.model,non_trainable=state.model)\n",
    "type(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWeights(trainable=ModelWeights(trainable=[array([[-0.01774468, -0.01918945, -0.01918945, ..., -0.01918945,\n",
       "        -0.01918945, -0.01679161],\n",
       "       [-0.01733185, -0.02059056, -0.02059056, ..., -0.02059056,\n",
       "        -0.02059056, -0.01706184],\n",
       "       [-0.01696984, -0.01977619, -0.01977619, ..., -0.0197762 ,\n",
       "        -0.0197762 , -0.01728554],\n",
       "       ...,\n",
       "       [-0.01874358, -0.02141564, -0.02141564, ..., -0.02141563,\n",
       "        -0.02141563, -0.01679137],\n",
       "       [-0.01881838, -0.02167221, -0.02167221, ..., -0.02167221,\n",
       "        -0.02167221, -0.01693343],\n",
       "       [-0.01859659, -0.02080034, -0.02080034, ..., -0.02080034,\n",
       "        -0.02080034, -0.0168134 ]], dtype=float32), array([-0.02047424, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.02162179,\n",
       "       -0.01232217, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.02275319, -0.01581776, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.02316058, -0.01596369, -0.01470376, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.01392745, -0.01627954, -0.01497598,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.00664263, -0.00800592,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.01643346, -0.01687382,\n",
       "       -0.02093915, -0.03095972, -0.03095972, -0.03095972, -0.0126312 ,\n",
       "       -0.01424935, -0.03095972, -0.03095972, -0.03095972, -0.01373998,\n",
       "       -0.03095972, -0.0144983 , -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.01375525, -0.01487663, -0.03095972, -0.00650989, -0.00814101,\n",
       "       -0.03095972, -0.01147992, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.01447882, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.00650846, -0.03095972, -0.01477187, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.01511315, -0.03095972, -0.01784018, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.01960814, -0.01158415, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.01744128],\n",
       "      dtype=float32)], non_trainable=[]), non_trainable=ModelWeights(trainable=[array([[-0.01774468, -0.01918945, -0.01918945, ..., -0.01918945,\n",
       "        -0.01918945, -0.01679161],\n",
       "       [-0.01733185, -0.02059056, -0.02059056, ..., -0.02059056,\n",
       "        -0.02059056, -0.01706184],\n",
       "       [-0.01696984, -0.01977619, -0.01977619, ..., -0.0197762 ,\n",
       "        -0.0197762 , -0.01728554],\n",
       "       ...,\n",
       "       [-0.01874358, -0.02141564, -0.02141564, ..., -0.02141563,\n",
       "        -0.02141563, -0.01679137],\n",
       "       [-0.01881838, -0.02167221, -0.02167221, ..., -0.02167221,\n",
       "        -0.02167221, -0.01693343],\n",
       "       [-0.01859659, -0.02080034, -0.02080034, ..., -0.02080034,\n",
       "        -0.02080034, -0.0168134 ]], dtype=float32), array([-0.02047424, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.02162179,\n",
       "       -0.01232217, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.02275319, -0.01581776, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.02316058, -0.01596369, -0.01470376, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.01392745, -0.01627954, -0.01497598,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.00664263, -0.00800592,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.01643346, -0.01687382,\n",
       "       -0.02093915, -0.03095972, -0.03095972, -0.03095972, -0.0126312 ,\n",
       "       -0.01424935, -0.03095972, -0.03095972, -0.03095972, -0.01373998,\n",
       "       -0.03095972, -0.0144983 , -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.01375525, -0.01487663, -0.03095972, -0.00650989, -0.00814101,\n",
       "       -0.03095972, -0.01147992, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.01447882, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.00650846, -0.03095972, -0.01477187, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.03095972,\n",
       "       -0.03095972, -0.01511315, -0.03095972, -0.01784018, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.01960814, -0.01158415, -0.03095972,\n",
       "       -0.03095972, -0.03095972, -0.03095972, -0.03095972, -0.01744128],\n",
       "      dtype=float32)], non_trainable=[]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weight Description\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OrderedDict([('num_examples', 200.0), ('loss', 3.3205395), ('accuracy', 0.155)])\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Model Evaluation Test Data \n",
    "train_metrics = evaluation(model_weights.trainable, federated_train_data)\n",
    "str(train_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef392b7373726638f25c5b5a9ae7a2125364017db5464905a5bcdac062fc1c56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
